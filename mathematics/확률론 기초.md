# 확률론 기초

- **목차**
  
  1. [확률의 단순한 정의와 이항계수](#1-확률의-단순한-정의와-이항계수)
  2. [확률의 성질](#2-확률의-성질)
     - 확률의 성질 2가지
     - 확률의 속성들
     - Birthday problem
  3. [조건부 확률](#3-조건부-확률)
     - 독립
     - 조건부 확률
     - 전체 확률의 법칙
     - 베이즈 정리
     - Monty Hall problem ( 수형도, 전체 확률의 법칙 풀이)
     - 심슨의 역설 (Simpson's Paradox)
  4. [확률변수](#4-확률변수-random-variable)
     - 도박꾼의 파산 (Gambler's ruin)
     - 확률질량함수 (PMF)
     - 누적분포함수 (CDF)
     - 베르누이 분포 (Bernoulli)
     - 이항분포 (Binomial)
     - 음이항분포 (Negative Binomial)
     - 초기하분포 (Hypergeometric)
     - 기하분포 (Geometric)
  5. [PMF와 CDF](#5-pmf와cdf)
     - 기댓값 (Means, Expected values)

# 1. 확률의 단순한 정의와 이항계수

- **용어 정리**

  - **표본 공간 (S, sample space)** : 어떤 시행에서 일어날 수 있는 모든 결과들의 모임

  - **사건 (event)** : 표본공간 (sample space)의 부분집합으로 어떤 조건을 만족하는 특정한 표본점들의 집합

    

- **확률의 단순한 정의 (Naive definition)**

  P(A)로 표기하며 ( 가능한 A의 결과의 수 ) / (가능한 모든 경우의 수)를 의미한다.

  - 확률의 분모는 유한한 값을 가져야 한다.

  - 단순한 정의로 해결할 수 있는 문제는 확률이 동일한 경우에만 해당한다.

    ex) 해왕성에 생물이 살 확률은? -> 단순한 정의에 의하면 산다/안산다 이므로 50%이다.

    50%의 확률은 말도 안되는 값임을 알 수 있다. 

    ex2) 해왕성에 지능을 가진 생물이 살 확률은 ? -> 마찬가지로 50%이다. 직관적으로 생각해봐도 생물이 살 확률보다 지능을 가진 생물이 살 확률이 훨씬 낮아야하지만 그렇지 않기에 문제가 된다.



- **이항계수 (Binomial Coeffecient)**

  자연수 n 및 정수 k가 주어졌을 때 **nCk** 또는 **C(n,k)** 로 표기한다.

  수식으로 나타내면 
  ![image](https://user-images.githubusercontent.com/71866756/147647425-56ac7a9c-61ec-4232-8bcd-45319eee6e7a.png)

  - 이항계수의 3가지 성질

    - C(n, k) = C(n, n-k) (이항계수의 정의를 이용해 증명 가능)

    - nC(n-1, k-1) = kC(n, k)

      증명) n명의 사람들 중 k명을 뽑고, 그 중 한명을 대표로 뽑는 경우를 생각할 수 있다. 

      ​		  (좌변) 대표를 먼저 뽑는 경우 : n명 중 1명 (n), n-1명 중 k-1명 ( C(n-1, k-1) )

      ​          (우변) k명을 먼저 뽑는 경우 : n명 중 k명 ( C(n, k) ), k명 중 1명 (k) 
      
    - 방데르몽드 항등식
    
    ![image](https://user-images.githubusercontent.com/71866756/147647465-25b2cc70-eaad-4c8a-ada3-82082c1039da.png)


  **!! 주의할 점 !!**

  10명 중 4명, 6명으로 두팀을 만든다고 하였을 때의 확률은 10C6=10C4이다.

  하지만, 10명 중 5명, 5명으로 두팀을 만든다고 하였을 때의 확률은 10C5 / 2가 된다.

  ( 두 팀을 완벽히 구분이 가능하다면 2로 나누지 않아도 되지만, 구분이 불가능할 경우 중복으로 counting이 되기 때문에 2로 나눠줘야 한다. )

  

  |                        | 순서상관있는 경우 | 순서상관없는 경우 |
  | ---------------------- | ----------------- | ----------------- |
  | **복원하는 경우**      | n^k               | n+k-1Ck           |
  | **복원하지 않는 경우** | nPk               | nCk               |

  - 순서상관없고, 복원하는 경우의 n+k-1Ck 증명

    ![image](https://user-images.githubusercontent.com/71866756/147635035-0e217ff2-4ec0-45f3-829b-c29895dcfa20.png)




# 2. 확률의 성질

- **확률의 성질 2가지**

  - 표본 공간 S, S의 사건 A를 입력으로 받았을 때, 0~1 사이의 값을 출력으로 갖는 함수 P가 있다고 했을 때, 만족하는 성질 2가지
  
  ![image](https://user-images.githubusercontent.com/71866756/147647362-3e1f6d3c-67e4-4fbe-9e80-e8181c5abfc8.png)
  
  
  
- **확률의 성질로 증명할 수 있는 속성들**

  - 공집합의 확률  
    ![image](https://user-images.githubusercontent.com/71866756/147647495-434be893-6920-460b-aa3b-1e0272e493d3.png)
  
  
  
- **여집합의 확률**  
    ![image](https://user-images.githubusercontent.com/71866756/147647507-c6d75e96-03d6-4c86-969a-5d83c221a881.png)
    
  - 포함 배제의 원리  
    ![image](https://user-images.githubusercontent.com/71866756/147647528-91d6125e-406a-40a7-a9a8-e1c798f2d966.png)
    - 증명  
    ![image](https://user-images.githubusercontent.com/71866756/147647546-b2a93ebb-ebca-450b-aa4c-362a0fe91f2d.png)
  
  
  
- **Birthday Problem**

  k명의 사람들 중 적어도 2명의 생일이 같은 확률이 50%가 넘는 k의 값은?

  ( 365일 중 태어날 확률은 모두 equally likely라고 가정하면 단순한 정의를 이용할 수 있다. )

  - k > 365일 경우

    **비둘기집의 원리**로 k>365보다 크면 적어도 한 쌍은 생일이 같을 수 밖에 없다. 

  - k <= 365일 경우

    : 직관적으로 생각해보면 365일 중 생일이 같은 확률은 크다고 생각되지 않는다. 하지만 이 문제의 정답은 23명이다. 

    P(생일이 모두 다를 경우) = ( 365x364x...x(365-k+1) ) / ( 365^k ) 으로 나타낼 수 있다. 

    P( 생일이 적어도 한명 같은 경우 ) = 1 - P(생일이 모두 다를 경우) 가 된다. 

    따라서 **k=23일 경우 확률은 약 50.7%**, **k=100일 경우 약 99.999%**가 나온다.

    -> 이 문제를 조금 다른 시각으로 보면 k=23일 때, 23C2로 생일이 같은 경우의 조합의 수를 생각해볼 수 있다. 23C2 = 253으로 상당히 많은 경우의 수가 나올 수 있다. 이러한 시각으로 봤을 때, 두명의 생일이 같을 확률은 꽤 크다고 볼 수 있다.

     ```c++
     // 실제 코드로 작성하여 난수 생성하여 실험해본 결과 50%에 육박하게 나오는 것을 확인할 수 있었다. 
     #include <iostream>
     #include <cstdlib>
     #include <map>
     #include <ctime>
     using namespace std;
     
     int main() {
     	int cnt = 0;
     	srand((unsigned int)time(NULL));
     	for (int k = 0; k < 10; k++) {
     		for (int j = 0; j < 1000; j++) {
     			map<int, int> m;
     			for (int i = 0; i < 23; i++) {
     				int temp = rand() % 365 + 1;
     				if (m[temp] != 0) {
     					m[temp] += 1;
     					cnt++;
     					break;
     				}
     				else m[temp] = 1;
     			}
     		}
     		cout << k+1 << "번째 확률 : " << (double)cnt / (double)1000 << endl;
     		cnt = 0;
     	}
     }
     ```

     ![image](https://user-images.githubusercontent.com/71866756/147647720-edcfb2e0-c2b3-4cab-93c0-00d91fe0fb5a.png)

# 3. 조건부 확률

- **독립**

  사건 A,B는 P(A,B)=P(A)P(B)일 경우, 독립이라고 한다. 

  

- **조건부 확률**

  사건 B가 발생했을 때 A가 발생할 확률로 만약 A와 B가 독립이 아닌 경우 매우 유용하다. 

  **!!! 중요 !!!** 

  여기서 P(B)로 나눠주는 이유는 B를 이미 발생한 사건으로 보고 A가 발생할 확률을 구하는 것이기 때문에 전체 표본 공간이었던 S가 B로 축소되고 이를 정규화하기 위해 P(B)로 나누어주는 것이다.   
  ![image](https://user-images.githubusercontent.com/71866756/148025973-9d076724-c5b6-43a0-a0d6-016fc3a20441.png)

   

  A와 B가 독립인 경우는 아래 수식으로 나타낼 수 있다.  
  ![image](https://user-images.githubusercontent.com/71866756/148026015-d4f72e20-3aad-44a9-bf8e-c023a9ca0c8f.png)

  - 정리

    ![image](https://user-images.githubusercontent.com/71866756/148026040-7f09ce2d-b65e-4b3f-bde4-5023e196827e.png)
    
    

- **전체 확률의 법칙 (law of total probability)**

  어려운 문제를 간단하게 쪼개어 해결하는 방법 중에 하나로 생각할 수 있다. 

  **조건부 확률**로부터 **조건이 붙지 않은 확률**을 계산할 때 사용할 수 있다.  

  (즉, P(B)를 B와 A의 조건부 확률로부터 계산 가능)

  ![image](https://user-images.githubusercontent.com/71866756/148051555-6f0b4b21-10a2-470b-a83a-8ad32a46b559.png)

- **베이즈 정리**  
  ![image](https://user-images.githubusercontent.com/71866756/148051588-34647411-7177-4a52-acd0-af68feac22e7.png)

  - 사전 확률 (P(A), prior) : 주어진 확률

  - 사후 확률 (P(A|B), posterior) : 구하는 확률

  - 조건부 독립 (conditional independence) : 사건 A,B가 사건 C가 주어졌을 경우 독립인 상황
    ![image](https://user-images.githubusercontent.com/71866756/148051622-73dda008-b933-4d76-b000-96498346ae99.png)

  **!!! 주의 !!!**

   조건부 독립과 독립은 별개이다. 독립이라고 해서 무조건 조건부 독립이 아니고, 조건부 독립이라고 해서 무조건 독립인 것도 아니다. 

  

  **EX)** 질병이 걸릴 확률은 1%이고 test가 정확한 확률은 95%일 때, 실제 질병에 걸렸을 확률은?

  P(D) : 질병에 걸렸을 확률

  P(T) : 테스트 결과 질병에 걸렸을 확률

  P(T|D) = 0.95  
  ![image](https://user-images.githubusercontent.com/71866756/148051650-2cf0cb58-ae61-4864-bce4-cf7044ad1e56.png)  
  => 실제 질병에 걸렸을 확률은 0.16으로 매우 낮은 값을 보인다. 

  => 직관적으로는 test 정확도가 높기 때문에 test결과 질병에 걸렸다고 나왔을 경우, 실제 질병에 걸렸을 확률은 더욱 높을 것으로 예상하지만 **직관과는 정반대의 결과**를 보인다.

  => 이는 test 정확도에 치중하여 생각하기 때문이다. 실제로 **병의 발생확률도 고려**해야 하기 때문에 이와 같은 결과를 보이는 것이다. 



- **Monty Hall 문제**

  - 수형도를 이용하여 풀이한 경우

    ![image](https://user-images.githubusercontent.com/71866756/148051687-286a83c1-39e1-4aa2-8f19-f1a5d59e20da.png)  

    

  - 전체 확률의 법칙을 이용한 경우

    S : 차를 뽑는 경우 (가정은 항상 선택을 바꾼다.)

    Dj : j번 문 뒤에 차가 있는 경우

    !! 처음에 1번 문을 선택한다고 가정하자 !!
    ![image](https://user-images.githubusercontent.com/71866756/148051761-b229105b-40bc-4eb9-9a71-21c9ccfc95bb.png)  



- **심슨의 역설 (Simpson's Paradox)**

  개별적인 항목에서 항상 뛰어난 결과여도 항목들의 합에서는 반대의 결과가 나타난다는 paradox

  | Person1  | 심장 수술 | 붕대풀기 | Person2  | 심장 수술 | 붕대풀기 |
  | -------- | --------- | -------- | -------- | --------- | -------- |
  | **성공** | 70        | 10       | **성공** | 2         | 81       |
  | **실패** | 20        | 0        | **실패** | 8         | 9        |

  - 위 케이스를 살펴보면 Person1의 각각의 항목의 성공률이 Person2보다 높은 것을 알 수 있다.

    ( 조건부 ) 

  - 하지만 전체 항목의 합은 Person1은 80%, Person2는 83%로 Person2가 높은 것을 알 수 있다. 

    ( 비조건부 )

  - A : surgery succeed, B : Person2이 수술, C : 심장 수술

    수식으로 표현하자면 아래처럼 될 것이다.   
    ![image](https://user-images.githubusercontent.com/71866756/148051795-8e30d406-617d-4da7-91ef-a5fd30e5b492.png)  
  
  - 이것이 심슨의 역설이다. 이것이 잘못된 이유는 아래 식으로 볼 수 있다.   
    ![image](https://user-images.githubusercontent.com/71866756/148051824-ed4d6db5-e32c-4e5f-8249-fbc826ecfbb0.png)  
    여기서 P(C|B)와 P(C^c|B)는 가중치라고 생각할 수 있는데, Person2가 해당 수술을 얼마나 진행했는지 나타내는 확률이다. 이 값이 들어간다면 심슨의 역설은 성립하지 않게 된다. 이것이 심슨의 역설이 존재할 수 있게 만드는 이유이다.  

  **!!! 따라서 교란 요인 (위 예에서는 C) 을 고려하는 것이 매우 중요하다 !!!**



# 4. 확률변수 (Random Variable)

- **확률 변수란**

   확률 변수는 표본 공간에서 실수로 가는 함수이다. 간단하게 말하자면 임의의 확률 시행의 수치적인 "요약"이라고 할 수 있다. 꼭 전체 표본공간의 요약일 필요는 없다. 확률변수를 사용하는 이유는 다루기 어려운 표본 공간에서 다루기 쉬운 실수로 대응할 수 있기 때문이다. 

- **도박꾼의 파산 (Gambler's Ruin)**

  A와 B 두명의 도박꾼이 매 라운드 $1씩 걸고 도박을 한다. 이긴 사람은 상대방의 $1을 가져가고, 둘 중 한명이 가지고 온 돈이 바닥날 때까지 이 과정을 반복한다. 

  p = P(A가 어떤 라운드를 이긴다.)

  q = 1-p

  A는 i달러, B는 N-i 달러를 가지고 게임을 한다고 할 때,  
  ![image](https://user-images.githubusercontent.com/71866756/148051852-0330f16e-ab0f-44bc-9135-7b50343c7247.png)  
    _위 수식을 계차방정식이라고 한다. 미분 방정식의 discrete형태를 의미한다._ 

  - 계차방정식의 풀이  

    ![image](https://user-images.githubusercontent.com/71866756/148051886-2241ef94-aa29-4d6e-a2ca-6364109f8a43.png)



- **확률질량함수 (PMF, probability mass function)**

   사건의 발생확률을 구할 수 있으며, 이산확률일 경우에 사용된다. 
  $$
  PMF\space:\space(X=a_j)\space for\space all\space j\\
  \begin{aligned}
  PMF의\space 조건\quad  &1.\space P_j \leq 0\\
  &2.\space \sum_j P_j = 1
  \end{aligned}
  $$
  
- **누적분포함수 (CDF, cumulative distribution function)**

  확률질량함수는 이산확률일 경우에만 사용할 수 있지만, 누적분포함수는 연속확률일 경우에도 사용할 수 있기 때문에 좀 더 일반적이라고 할 수 있다. 
  $$
  F(x)=P(X\leq x)
  $$
  
- **이항정리 (Binomial theorem)**
  $$
  \begin{aligned}
  (a+b)^n&=nC_0a^n+nC_1a^{n-1}b+nC_2a^{n-2}b^2+...+nCnb^n\\
  &=\sum_{r=0}^{n}nC_ra^{n-r}b^r
  \end{aligned}
  $$
  
  
- **베르누이 분포 ( Bern(p), Bernoulli )**

  X가 0(실패), 1(성공) 두가지의 값만 가질 수 있으며, 

  **P(x=1)=p, P(x=0)=1-p**일 때, X는 _Bernoulli(p)_분포를 따른다고 한다.  

  시행전의 x는 무엇인지 모르지만, 시행 후에는 0 또는 1이 된다. 



- **이항분포 ( Bin(n,p), Binomial )**

  n번의 독립적인 베르누이(p) 시행에서 성공 횟수의 분포는 _Bin(n,p)_를 따른다고 한다. 

  - 확률질량함수 (PMF, probability mass function)  
    
    사건의 발생확률을 구할 수 있으며, **이산확률변수**에만 해당한다.![image](https://user-images.githubusercontent.com/71866756/148051921-76250018-702f-4f46-bb5f-f08cb1570f91.png)
    
    => 이항분포는 **이항정리**와 같은 형태로 PMF의 조건이 성립한다는 것을 알 수 있다. 
    $$
    \sum_{k=0}^{n}nC_kp^{n-r}q^r=(p+q)^n=1^n=1\quad 즉,\space 조건\space 만족
    $$
  
  
  
  - 지시확률변수 (indicator random variables)
  
    아래 수식처럼 발생하는 경우의 수를 모두 count하는 방법이다. 
  
    **iid** : independent, identically distributed ( X는 모두 같은 분포를 가지며 서로 독립이라는 의미)
    $$
    X=X_1+X_2+...+X_n\quad X_1,...X_n\space iid\sim Bern(p) \\
    X_j=성공인\space 경우\space 1,\space 실패인\space 경우\space 0
    $$
    
  
  - _X ~ Bin(n,p), Y ~ Bin(m,p)_ 이면서 X와 Y가 **독립**일 경우, _X+Y~Bin(n+m,p)_ 이다. 
    $$
    \begin{aligned}
    증명&)\\
    &=>X=X_1+...+X_n,\space Y=Y_1+...+Y_n\\
    &=>X+Y=\sum_{j=0}^nX_j+\sum_{i=0}^nY_i\\
    &=> sum\space of\space n+m\space iid\space Bern(p)\\
    &=> Bin(n+m,p)
    \end{aligned}
    $$
  
    $$
    \begin{aligned}
    증명1)\\
    &P(X+Y=k)\\&=\sum_{j=0}^kP(X+Y=k|X=j)P(X=j)\\
    &=\sum_{j=0}^kP(Y=k-j|X=j)nC_jp^jq^{n-j}\quad (X=j이므로 Y=k-j)\\
    &=\sum_{j=0}^kP(Y=k-j)nC_jp^jq^{n-j}\quad (X, Y는\space 독립)\\
    &=\sum_{j=0}^kmC_{k-j}p^{k-j}q^{n-k+j}nC_jp^jq^{n-j}\\
    &=p^kq^{m+n-k}\sum_{j=0}^kmC_{k-j}nC_j\\
    &=p^kq^{m+n-k}\sum_{j=0}^k{(m+n)}C_k\quad (방데르몽드\space 항등식)\\
    &=Bin(m+n,p)
    \end{aligned}
    $$
  
- **음이항분포 (NegBin(r,p), Negative Binomial)**

  여러 번의 Bern(p) 독립시행 중에서 r번째 성공까지의 실패 횟수를 나타낸다. 

  - PMF

    성공 확률 : p, 실패 확률 : q, 성공 횟수 : r, 실패 횟수 : n일 때, 마지막은 항상 성공이여야 하므로, 마지막 이전 시행들의 조합을 구하면 된다.  
    $$
    P(X=n)=\begin{pmatrix}n+r-1\\r-1\end{pmatrix}p^rq^n,\quad 0,1,2,...
    $$
    

- **초기하분포 (Hypergeometric)**

  **EX)** 하얀 돌과 검정돌이 각각 w개, b개 있다. 이중에서 하얀돌을 뽑는 확률 = X라고 할 때, 하얀돌을 k개 뽑는 확률을 구하라.  
  $$
  P(X=k)=\frac{wC_k*bC_{n-k}}{(w+b)C_n}
  $$
  => 이러한 분포를 초기하분포라고 한다. (비복원추출, 이 경우 독립적이지 않기 때문에 binomial일 수가 없다. )
  $$
  \begin{aligned}
  P(X=k)&=\sum_{k-0}^w\frac{wC_k*bC_{n-k}}{(w+b)C_n}\\
  &=\frac{1}{(w+b)C_n}\sum_{k-0}^w(w+b)C_n\quad (방데르몽드\space 항등식에\space 의해)\\
  &=\frac{(w+b)C_n}{(w+b)C_n}\\
  &=1
  \end{aligned}
  $$

- - 

- **기하분포 (Geom(p),Geometric)**

  독립적인 베르누이 시행에서 첫 성공 전의 실패 횟수를 count.

  - PMF
    $$
    P(X=k)=pq^k\\
    \sum_{k=0}^\infin pq^k=\frac {p}{1-q}=1로\space 성립\quad (등비수열\space 합:\frac {a(1-r^n)}{1-r})
    $$
    





# 5. PMF와CDF

- **이산확률분포에서의 CDF 그래프**

  <img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20220105160718909.png" alt="image-20220105160718909" style="zoom:50%;" />
  $$
  P(a<X\leq b)=F(b)-F(a)
  $$

  - !! CDF의 특징 !!

    - 증가함수이다. (증가하거나 같다, 감소할 수는 없다)

    - 우연속이다. 

      예를 들어, 2.x에서 2로 갈때 값이 바뀌지 않지만, 1.x에서 2로 갈 때는 값이 바뀐다.  

    - x가 음의 무한대로 갈 때, F(x)는 0으로 간다. 

      x가 양의 무한대로 갈 때, F(x)는 1로 간다.

      

- **CDF에서의 독립**
  $$
  P(X\leq x, Y\leq y)=P(X\leq x)P(Y\leq y)\quad (연속)\\
  P(X= x, Y= y)=P(X= x)P(Y= y)\quad (독립)
  $$
  위 식이 성립한다. 

- **기댓값 (Means, Expected values)**

  - 기댓값을 구하는 두가지 방법

    - 산수

    - 가중평균 (곱해지는 가중치가 다를 경우)

      비가중평균 (곱해지는 가중치가 모두 같을 경우)

    **EX)** 

    1,1,1,1,1,5,5,8의 합을 산수로 구하면 => (1+1+...+8)/8

    1,1,1,1,1,5,5,8의 합을 가중평균으로 구하면 => (5/8) * 1 + (2/8) * 5 + (1/8) * 8

    

  - 이산확률분포의 기댓값 ( E(X) )
    $$
    E(X)=\sum_xxP(X=x)
    $$

  - 선형성 (Linearity)
    $$
    1.\space E(X+Y)=E(X)+E(Y)\quad even\space if\space X,Y \space are\space dependent\\
    2.\space E(cX)=cE(X)
    $$
    1번 증명)

    ![image-20220105172137811](../../../../AppData/Roaming/Typora/typora-user-images/image-20220105172137811.png)
    $$
    \begin{aligned}
    E(X)&=\sum_xxP(X=x)\quad\quad\quad\quad\quad grouping   \\
    &=\sum_xX(s)P(\{s\})\quad\quad\quad\quad\quad ungrouped
    \end{aligned}
    $$
    => grouping의 경우 가중평균으로 기댓값을 구하는 것이고, ungrouped의 경우 산수로 구하는 것이라고 생각할 수 있다. 

    => ungrouped의 경우 (0+0+0+0+1+1+2+2+2+3)*(1/10)이라고 표현할 수 있다. 

    따라서 아래 식처럼 증명할 수 있다. (T=X+Y)

    <img src="../../../../AppData/Roaming/Typora/typora-user-images/image-20220105172307119.png" alt="image-20220105172307119" style="zoom: 80%;" />



| 분포                       | 기댓값 | 분산 |
| -------------------------- | ------ | ---- |
| 베르누이 (Bernoulli)       | p      |      |
| 이항 (Binomial)            | np     |      |
| 음이항 (Negative Binomial) | (rq)/p |      |
| 기하 (Geometric)           | q/p    |      |

1. 이항분포 기대값 증명

$$
\begin{aligned}
E(X)&=\sum_{k=0}^nk*nC_kp^kq^{n-k}\\
&=np\sum_{k=0}^n(n-1)C_{(k-1)}p^{k-1}q^{n-k}\quad (이항계수\space 두번째\space 성질)\\
&=np\quad (이항분포의\space 정의에\space 따라\space 뒤의\space 항=1)
\end{aligned}
$$

2. 음이항분포 기대값 증명
   $$
   \begin{aligned}
   E(X)&=E(X_1+...+X_r)\quad\quad\quad (X_j:j-1번\space 시행에서\space j번\space 시행까지의\space 실패횟수)\\
   &=E(X_1)+...+E(X_r)\quad (X_j\sim Geom(p)이므로\space  E(X_j)=\frac {q}{p})\\
   &=\frac {rq}{p} 
   \end{aligned}
   $$
   

3. 기하분포 기대값 증명
   $$
   \begin{aligned}
   E(X)&=\sum_{k=0}^nkpq^k\\
   &=p\sum_{k=1}^\infin kq^k\\
   &=\frac {pq}{p^2}\quad (1번에\space 의해)\\
   &=\frac {q}{p}
   \\
   (\space 1번&=> \sum_{k=0}^\infin q^k = \frac{1}{1-q}\quad (양변\space 미분)\\
   &=>\sum_{k=1}^\infin kq^{k-1}=\frac {1}{(1-q)^2}\quad (양변\space k곱하기)\\
   &=> \sum_{k=1}^\infin kq^{k}=\frac {q}{(1-q)^2})
   \end{aligned}
   $$
   

 
