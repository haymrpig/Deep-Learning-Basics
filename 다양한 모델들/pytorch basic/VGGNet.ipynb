{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLeFrr8v07ot"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import utils\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "Is-O_-iG0_q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "ydvlgOgp1l2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(777)\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.manual_seed_all(777)"
      ],
      "metadata": {
        "id": "kLj6Srf51uFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                   transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                          train=True,\n",
        "                                          download=True,\n",
        "                                          transform = my_transform)\n",
        "val_data = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                          train=False,\n",
        "                                          download=True,\n",
        "                                          transform = my_transform)\n",
        "train_loader = DataLoader(train_data, batch_size=512, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_data, batch_size=4,num_workers=2)\n"
      ],
      "metadata": {
        "id": "9C7YivkF11tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "owJzalL-2fpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def imshow(img):\n",
        "    img = img/2+0.5\n",
        "    plt.imshow(img.permute(1,2,0).numpy())\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "x_grid = utils.make_grid(images[:512], nrow=32, padding=2)\n",
        "\n",
        "imshow(x_grid)\n"
      ],
      "metadata": {
        "id": "-qZedU4q2v3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ipywidgets import interact\n",
        "\n",
        "@interact(idx=(0,train_data.data.shape[0]-1))\n",
        "def showImg(idx):\n",
        "    plt.imshow(train_data.data[idx])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "I23sojkX3Lpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models.vgg as vgg"
      ],
      "metadata": {
        "id": "aEhZiJX85C0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = [32,32,'M',64,64,128,128,128,'M',256,256,256,512,512,512,'M']"
      ],
      "metadata": {
        "id": "6LuMctrQ9CKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG(nn.Module):\n",
        "    def __init__(self, features, num_classes=1000,init_weights=True):\n",
        "        super().__init__()\n",
        "        self.features = features\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512*4*4, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096,4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096,num_classes),\n",
        "        )\n",
        "        if init_weights:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.features(x)\n",
        "        x=x.view(x.size(0), -1)\n",
        "        x=self.classifier(x)\n",
        "        return x\n",
        "    \n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)"
      ],
      "metadata": {
        "id": "jmkyoXte9Q1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16=VGG(vgg.make_layers(cfg),10,True).to(device)"
      ],
      "metadata": {
        "id": "mCbbEQOz-1db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.Tensor(1,3,32,32).to(device)\n",
        "out = vgg16(a)\n",
        "print(out)"
      ],
      "metadata": {
        "id": "N4z5WA_X_ADY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.SGD(vgg16.parameters(), lr = 0.005, momentum=0.9)\n",
        "\n",
        "lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)\n",
        "# 5번의 step마다 learning rate에 gamma값을 곱해준다."
      ],
      "metadata": {
        "id": "-Y8k-YaJLjzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "epochs = 50\n",
        "\n",
        "best_loss = float('inf')\n",
        "best_model_wts = copy.deepcopy(vgg16.state_dict())\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    lr_sche.step()\n",
        "    for i, data in tqdm(enumerate(train_loader, 0)):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = vgg16(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    if( running_loss < best_loss ):\n",
        "        best_loss = running_loss\n",
        "        best_model_wts = copy.deepcopy(vgg16.state_dict())\n",
        "        torch.save(best_model_wts,'./weight/weights.pth')\n",
        "        "
      ],
      "metadata": {
        "id": "KQRhPm6xMFcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = VGG(vgg.make_layers(cfg),10,True)\n",
        "new_model.to(device)\n",
        "new_model.load_state_dict(torch.load('./weight/weights.pth'))"
      ],
      "metadata": {
        "id": "MTbX9Ur-S-9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_iter = iter(val_loader)\n",
        "images, labels = val_iter.next()\n",
        "outputs = new_model(images.to(device))\n",
        "outputs = torch.argmax(outputs, dim=1)\n",
        "list_answers = [ outputs == labels.to(device).view_as(outputs) ]\n",
        "for i in range(outputs.size(0)):\n",
        "    print( classes[labels[i]], classes[outputs[i]])\n"
      ],
      "metadata": {
        "id": "Sv-vBmdjNIgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Y5bhogTAVYnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "U_Y55Qo2UKtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "j2NDPlPDVGV7"
      }
    }
  ]
}