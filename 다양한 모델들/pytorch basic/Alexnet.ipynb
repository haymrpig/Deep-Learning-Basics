{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alexnet.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjXfv6GGXOCe"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "NUM_EPOCHS = 90\n",
        "BATCH_SIZE = 128\n",
        "MOMENTUM = 0.9\n",
        "LR_DECAY = 0.0005\n",
        "LR_INIT = 0.01\n",
        "IMAGE_DIM = 227\n",
        "NUM_CLASSES = 100"
      ],
      "metadata": {
        "id": "PnyQA-W0_ZeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob\n",
        "base_path = '/content/gdrive/MyDrive'\n",
        "folder = 'CiFAR10_datasets'\n",
        "path_list = [base_path, folder]\n",
        "path = os.path.join(*path_list)\n",
        "\n",
        "os.chdir(base_path)\n",
        "if os.path.exists(folder):\n",
        "    print(\"folder already exists!\")\n",
        "else:\n",
        "    os.makedirs(folder)\n",
        "    print(\"folder create complete!\")"
      ],
      "metadata": {
        "id": "lt4A0TISEWpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root=path,\n",
        "                                              train=True,\n",
        "                                              download=True,\n",
        "                                              transform=transform)\n",
        "val_dataset = torchvision.datasets.CIFAR10(root=path,\n",
        "                                            train=False,\n",
        "                                            download=True,\n",
        "                                            transform=transform)\n",
        "\n",
        "train_mean = train_dataset.data.mean(axis=(0,1,2))      # 축의 평균을 구할 때는 축을 없앤다고 생각하면 편하다.\n",
        "                                                        # 3 channel에 대한 각각의 평균을 구하고 싶으니\n",
        "                                                        # (batch, h, w, channel)에서 0,1,2축을 없애면 된다.\n",
        "train_std = train_dataset.data.std(axis=(0,1,2))\n",
        "val_mean = val_dataset.data.mean(axis=(0,1,2))\n",
        "val_std = val_dataset.data.std(axis=(0,1,2))\n",
        "\n",
        "train_mean = train_mean/255\n",
        "train_std = train_std/255\n",
        "\n",
        "val_mean = val_mean/255\n",
        "val_std = val_std/255\n",
        "transform_train = transforms.Compose([\n",
        "                                      transforms.Resize((227,227)),\n",
        "                                   transforms.CenterCrop(IMAGE_DIM),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize(train_mean,train_std),\n",
        "])\n",
        "transform_val = transforms.Compose([\n",
        "                                    transforms.Resize((227,227)),\n",
        "                                   transforms.CenterCrop(IMAGE_DIM),\n",
        "                                   transforms.ToTensor(),\n",
        "                                   transforms.Normalize(val_mean,val_std),\n",
        "])\n",
        "train_dataset = torchvision.datasets.CIFAR10(root=path,\n",
        "                                              train=True,\n",
        "                                              download=True,\n",
        "                                              transform=transform_train)\n",
        "val_dataset = torchvision.datasets.CIFAR10(root=path,\n",
        "                                            train=False,\n",
        "                                            download=True,\n",
        "                                            transform=transform_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "ewYlPG2jGxdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=100):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4),\n",
        "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            \n",
        "            nn.Conv2d(96,256,kernel_size=5, stride=1,padding=2),\n",
        "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(in_features=(256*6*6), out_features=4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(in_features=4096, out_features=4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(in_features=4096, out_features=num_classes),\n",
        "        )\n",
        "\n",
        "        self.init_bias()\n",
        "\n",
        "    def init_bias(self):\n",
        "        for m in self.net:\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.normal_(m.weight, mean=0, std=0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            nn.init.constant_(self.net[4].bias, 1)\n",
        "            nn.init.constant_(self.net[10].bias, 1)\n",
        "            nn.init.constant_(self.net[12].bias, 1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.net(x)\n",
        "        x=x.view(x.shape[0], -1)\n",
        "        x=self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "wr8tJ507Akg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(7777)\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.manual_seed_all(7777)\n",
        "\n",
        "model = AlexNet(10).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.SGD(params=model.parameters(), lr=LR_INIT, momentum=MOMENTUM, weight_decay=LR_DECAY)\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
        "val_every = 1"
      ],
      "metadata": {
        "id": "XyZrIfbPEVii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(num_epochs, model, data_loader, criterion, optimizer, saved_dir, val_every, device):\n",
        "    print('start training..')\n",
        "    best_loss = 9999999\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (imgs, labels) in enumerate(data_loader):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)            \n",
        "            loss.backward()     \n",
        "            optimizer.step()\n",
        "\n",
        "            _, argmax = torch.max(outputs, 1)\n",
        "            accuracy = (labels==argmax).float().mean()\n",
        "\n",
        "            if (i+1)%10==0:\n",
        "                print(\"Epoch [{}/{}], Step[{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%, learning rate : {}\".format(epoch+1, num_epochs, i+1, len(data_loader), loss.item(), accuracy.item()*100, get_lr(optimizer)))\n",
        "        if (epoch + 1) % val_every == 0:\n",
        "            avg_loss = validation(epoch+1, model, val_loader, criterion, device)\n",
        "            if avg_loss < best_loss:\n",
        "                print( \"Best performance at epoch:{}\".format(epoch+1))\n",
        "                print( \"Save model in\", saved_dir)\n",
        "                best_loss = avg_loss\n",
        "                save_model(model, saved_dir)"
      ],
      "metadata": {
        "id": "N806h28tQPCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation(epoch, model, data_loader, criterion, device):\n",
        "    print(\"Start validation #{}\".format(epoch))\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        total = 0\n",
        "        total_loss = 0\n",
        "        cnt = 0\n",
        "        correct = 0\n",
        "        for i, (images, labels) in enumerate(data_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss\n",
        "            total += images.size(0)\n",
        "\n",
        "            _, predict = torch.max(outputs, 1)\n",
        "            correct += (labels==predict).sum().item()\n",
        "            cnt += 1\n",
        "        avg_loss = total_loss / cnt\n",
        "        print(\"Validation #{} Accuracy: {:.2f}% Average Loss: {:.4f}\".format(epoch, correct/total*100, avg_loss))\n",
        "    model.train()\n",
        "    return avg_loss\n"
      ],
      "metadata": {
        "id": "Q1R0FSMBZaRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lr(opt):\n",
        "    for param_group in opt.param_groups:\n",
        "        return param_group['lr']"
      ],
      "metadata": {
        "id": "arlxQuaVnUee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, saved_dir, file_name='best_model.pt'):\n",
        "    os.makedirs(saved_dir, exist_ok=True)   # 해당 디렉토리가 존재할 시 에러를 반환하지 않는다.\n",
        "    check_point = {\n",
        "        'net': model.state_dict()\n",
        "    }\n",
        "    output_path = os.path.join(saved_dir, file_name)\n",
        "    torch.save(check_point, output_path)"
      ],
      "metadata": {
        "id": "iokBF8gObTz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(100, model, train_loader, criterion, optimizer, path, val_every, device)"
      ],
      "metadata": {
        "id": "qe-9D3bVN55E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}